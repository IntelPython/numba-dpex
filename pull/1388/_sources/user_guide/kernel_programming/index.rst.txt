.. _index:
.. include:: ./../../ext_links.txt

Kernel Programming
==================

The tutorial covers the numba-dpex kernel programming API (kapi) and introduces
the concepts needed to write data-parallel kernels in numba-dpex.


.. Preliminary concepts
.. --------------------

.. Data parallelism
.. ++++++++++++++++

.. Single Program Multiple Data
.. ++++++++++++++++++++++++++++

.. Range v/s Nd-Range Kernels
.. ++++++++++++++++++++++++++

.. Work items and Work groups
.. ++++++++++++++++++++++++++

Core concepts
-------------


Writing a *range* kernel
++++++++++++++++++++++++

A *range* kernel represents the simplest form of parallelism that can be
expressed in numba-dpex using kapi. Such a kernel represents a data-parallel
execution over a set of work items with each work item representing a logical
thread of execution. :ref:`ex_vecadd_kernel` shows an example of a range kernel
written in numba-dpex.

.. code-block:: python
    :linenos:
    :caption: **EXAMPLE:** Vector addition using a range kernel
    :name: ex_vecadd_kernel
    :emphasize-lines: 9,17

    import dpnp
    import numba_dpex.experimental as dpex
    from numba_dpex import kernel_api as kapi


    # Data parallel kernel implementing vector sum
    @dpex.kernel
    def vecadd(item: kapi.Item, a, b, c):
        i = item.get_id(0)
        c[i] = a[i] + b[i]


    N = 1024
    a = dpnp.ones(N)
    b = dpnp.ones_like(a)
    c = dpnp.zeros_like(a)
    dpex.call_kernel(vecadd, kapi.Range(N), a, b, c)

The highlighted lines in the example demonstrate the definition of the execution
range on **line 17** and extraction of every work items' *id* or index position
via the ``item.get_id`` call on **line 10**. An execution range comprising of
1024 work items is defined when calling the kernel and each work item then
executes a single addition. Note that the array sizes for the input and output
arguments are equal to the size of the execution range. For very large arrays,
the design will not scale as there is usually an upper bound for the range size
depending on device. For most current Intel GPU devices, the maximum range size
is 2^32 and a kernel requesting more work items than that bound will not
execute. As such, programmers need to consider the size of the data and the
access patterns for their kernels before scheduling a range kernel. The maximum
number of work items can be queried programmatically as shown in
:ref:`ex_max_work_item`.

.. code-block:: python
    :linenos:
    :caption: **EXAMPLE:** Query maximum number of work items for a device
    :name: ex_max_work_item

    import dpctl
    import math

    d = dpctl.SyclDevice("gpu")
    d.print_device_info()

    max_num_work_items = (
        d.max_work_group_size
        * d.max_work_item_sizes1d[0]
        * d.max_work_item_sizes2d[0]
        * d.max_work_item_sizes3d[0]
    )
    print(max_num_work_items, f"(2^{int(math.log(max_num_work_items, 2))})")

    cpud = dpctl.SyclDevice("cpu")
    cpud.print_device_info()

    max_num_work_items_cpu = (
        cpud.max_work_group_size
        * cpud.max_work_item_sizes1d[0]
        * cpud.max_work_item_sizes2d[0]
        * cpud.max_work_item_sizes3d[0]
    )
    print(max_num_work_items_cpu, f"(2^{int(math.log(max_num_work_items_cpu, 2))})")

The output for :ref:`ex_max_work_item` on a system with an Intel Gen9 integrated
graphics processor and a 9th Generation Coffee Lake CPU is shown in
:ref:`ex_max_work_item_output`.

.. code-block:: bash
    :caption: **OUTPUT:** Query maximum number of work items for a device
    :name: ex_max_work_item_output

        Name            Intel(R) UHD Graphics 630 [0x3e98]
        Driver version  1.3.24595
        Vendor          Intel(R) Corporation
        Filter string   level_zero:gpu:0

    4294967296 (2^32)
        Name            Intel(R) Core(TM) i7-9700 CPU @ 3.00GHz
        Driver version  2023.16.12.0.12_195853.xmain-hotfix
        Vendor          Intel(R) Corporation
        Filter string   opencl:cpu:0

    4503599627370496 (2^52)



There are a few semantic rules that have to be adhered to when writing a range
kernel:

* Analogous to the API of SYCL a range kernel can execute only over a 1-, 2-, or
  a 3-dimensional set of work items.

* Every range kernel requires its first argument to be an instance of the
  :class:`numba_dpex.kernel_api.Item` class. The ``Item`` object is an
  abstraction encapsulating the index position (id) of a single work item in the
  global execution range. The id will be a 1-, 2-, or a 3-tuple depending
  the dimensionality of the execution range.

* A range kernel cannot return any value.

  **Note** the rule is enforced only in
  the compiled mode and not in the pure Python execution on a kapi kernel.

* A kernel can accept both array and scalar arguments. Array arguments currently
  can either be a ``dpnp.ndarray`` or a ``dpctl.tensor.usm_ndarray``. Scalar
  values can be of any Python numeric type. Array arguments are passed by
  reference, *i.e.*, changes to an array in a kernel are visible outside the
  kernel. Scalar values are always passed by value.


A range kernel has to be executed by calling the
:py:func:`numba_dpex.experimental.launcher.call_kernel` function. The execution
range for the kernel is specified by creating an instance of a
:class:`numba_dpex.kernel_api.Range` class and passing the ``Range`` object as
an argument to ``call_kernel``. The ``call_kernel`` function does three things:
compiles the kernel if needed, "unboxes" all kernel arguments by converting
CPython objects into numba-dpex objects, and finally submitting the kernel to an
execution queue with the specified execution range. Refer the API documentation
for further details.

A range kernel is meant to express a basic `parallel-for` calculation that is
ideally suited for embarrassingly parallel kernels such as elementwise
computations over n-dimensional arrays (ndarrays). The API for expressing a
range kernel does not allow advanced features such as synchronization of work
items and fine-grained control over memory allocation on a device. For such
advanced features, an nd-range kernel should be used.

.. seealso::
    Refer API documentation for :class:`numba_dpex.kernel_api.Range`,
    :class:`numba_dpex.kernel_api.Item`,  and
    :func:`numba_dpex.experimental.launcher.call_kernel` for more details.

Writing an *nd-range* kernel
++++++++++++++++++++++++++++

In a range kernel, the kernel execution is scheduled over a set of work items
without any explicit grouping of the work items. The basic form of parallelism
that can be expressed using a range kernel does not allow expressing any notion
of locality within the kernel. To get around that limitation, kapi provides a
second form of expressing a parallel kernel that is called an *nd-range* kernel.
An nd-range kernel represents a data-parallel execution of the kernel by a set
of explicitly defined groups of work items. An individual group of work items is
called a *work group*. :ref:`ex_matmul_kernel` demonstrates an nd-range kernel
and some of the advanced features programmers can use in this type of kernel.

.. code-block:: python
    :linenos:
    :caption: **EXAMPLE:** Sliding window matrix multiplication as an nd-range kernel
    :name: ex_matmul_kernel

    from numba_dpex import kernel_api as kapi
    import numba_dpex.experimental as dpex_exp
    import numpy as np
    import dpctl.tensor as dpt

    square_block_side = 2
    work_group_size = (square_block_side, square_block_side)
    dtype = np.float32


    @dpex_exp.kernel
    def matmul(
        nditem: kapi.NdItem,
        X,  # IN READ-ONLY    (X_n_rows, n_cols)
        y,  # IN READ-ONLY    (n_cols, y_n_rows),
        X_slm,  # SLM to store a sliding window over X
        Y_slm,  # SLM to store a sliding window over Y
        result,  # OUT        (X_n_rows, y_n_rows)
    ):
        X_n_rows = X.shape[0]
        Y_n_cols = y.shape[1]
        n_cols = X.shape[1]

        result_row_idx = nditem.get_global_id(0)
        result_col_idx = nditem.get_global_id(1)

        local_row_idx = nditem.get_local_id(0)
        local_col_idx = nditem.get_local_id(1)

        n_blocks_for_cols = n_cols // square_block_side
        if (n_cols % square_block_side) > 0:
            n_blocks_for_cols += 1

        output = dtype(0)

        gr = nditem.get_group()

        for block_idx in range(n_blocks_for_cols):
            X_slm[local_row_idx, local_col_idx] = dtype(0)
            Y_slm[local_row_idx, local_col_idx] = dtype(0)
            if (result_row_idx < X_n_rows) and (
                (local_col_idx + (square_block_side * block_idx)) < n_cols
            ):
                X_slm[local_row_idx, local_col_idx] = X[
                    result_row_idx, local_col_idx + (square_block_side * block_idx)
                ]

            if (result_col_idx < Y_n_cols) and (
                (local_row_idx + (square_block_side * block_idx)) < n_cols
            ):
                Y_slm[local_row_idx, local_col_idx] = y[
                    local_row_idx + (square_block_side * block_idx), result_col_idx
                ]

            kapi.group_barrier(gr)

            for idx in range(square_block_side):
                output += X_slm[local_row_idx, idx] * Y_slm[idx, local_col_idx]

            kapi.group_barrier(gr)

        if (result_row_idx < X_n_rows) and (result_col_idx < Y_n_cols):
            result[result_row_idx, result_col_idx] = output


    def _arange_reshaped(shape, dtype):
        n_items = shape[0] * shape[1]
        return np.arange(n_items, dtype=dtype).reshape(shape)


    X = _arange_reshaped((5, 5), dtype)
    Y = _arange_reshaped((5, 5), dtype)
    X = dpt.asarray(X)
    Y = dpt.asarray(Y)
    device = X.device.sycl_device
    result = dpt.zeros((5, 5), dtype, device=device)
    X_slm = kapi.LocalAccessor(shape=work_group_size, dtype=dtype)
    Y_slm = kapi.LocalAccessor(shape=work_group_size, dtype=dtype)

    dpex_exp.call_kernel(matmul, kapi.NdRange((6, 6), (2, 2)), X, Y, X_slm, Y_slm, result)


When writing an nd-range kernel, a programmer
defines a set of groups of work items instead of a flat execution range

An nd-range kernel needs to be launched with
an instance of the :py:class:`numba_dpex.kernel_api.NdRange` class and the first
argument to an nd-range kernel has to be an instance of
:py:class:`numba_dpex.kernel_api.NdItem`. An ``NdRange`` object defines a set of
work groups each with it own set of work items.


The ``device_func`` decorator
+++++++++++++++++++++++++++++

Supported mathematical operations
+++++++++++++++++++++++++++++++++

Supported Python operators
++++++++++++++++++++++++++

Supported kernel argument types
+++++++++++++++++++++++++++++++

Launching a kernel
++++++++++++++++++

Advanced concepts
-----------------

Local memory allocation
+++++++++++++++++++++++

Private memory allocation
+++++++++++++++++++++++++

Group barrier synchronization
+++++++++++++++++++++++++++++

Atomic operations
+++++++++++++++++

Async kernel execution
++++++++++++++++++++++

Specializing a kernel or a device_func
++++++++++++++++++++++++++++++++++++++
