<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>How to select device to offload kernels &mdash; numba-dppy 0+untagged.652.gc23150e.dirty documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Reduction on SYCL-supported Devices" href="reduction.html" />
    <link rel="prev" title="Supported Atomic Operations" href="atomic-operations.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> numba-dppy
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Core Features</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../CoreFeatures.html">Code-generation based on a device</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CoreFeatures.html#automatic-offload-of-numpy-expressions">Automatic offload of NumPy expressions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guides</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html"> Getting Started</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html"> Programming SYCL Kernels</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="writing_kernels.html">Writing SYCL Kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="memory-management.html">Memory Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="synchronization.html">Synchronization Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="device-functions.html">Writing Device Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="atomic-operations.html">Supported Atomic Operations</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">How to select device to offload kernels</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#example">Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="reduction.html">Reduction on SYCL-supported Devices</a></li>
<li class="toctree-l2"><a class="reference internal" href="ufunc.html">Universal Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="supported-python-features.html">Supported Python Features in a <code class="docutils literal notranslate"><span class="pre">numba-dppy</span></code> Kernel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../debugging/index.html"> Debugging with GDB</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migrating_from_numba_cuda.html"> numba-dppy for numba.cuda Programmers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../developer_guides/dpnp_integration.html">DPNP integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer_guides/tools.html">Debugging the compilation pipeline</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">numba-dppy</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">Programming SYCL Kernels Using <code class="xref py py-func docutils literal notranslate"><span class="pre">kernel()</span></code></a> &raquo;</li>
      <li>How to select device to offload kernels</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/user_guides/kernel_programming_guide/selecting_device.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="how-to-select-device-to-offload-kernels">
<h1>How to select device to offload kernels<a class="headerlink" href="#how-to-select-device-to-offload-kernels" title="Permalink to this headline"></a></h1>
<p>Numba-dppy supports passing two types of arrays alongside scalars to a &#64;numba_dppy.kernel decorated function. Depending on the array argument users will need to use different method to select the device for computation.</p>
<p>The two types are:</p>
<ol class="arabic simple">
<li><p>numpy.ndarray.</p></li>
<li><p>Any array with __sycl_usm_array_interface__ (SUAI) attribute.</p></li>
</ol>
<p><strong>Users are not allowed to pass mixed type of arrays to a &#64;numba_dppy.kernel.</strong> For example, if the first array argument to a &#64;numba_dppy.kernel is of type <code class="code docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>, the rest of the array argument will also have to of type <code class="code docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>.</p>
<p>The following are how users can specify in which device they want to offload their computation.</p>
<ul>
<li><dl class="simple">
<dt><code class="code docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></dt><dd><p>Using context manager, <code class="code docutils literal notranslate"><span class="pre">with</span> <span class="pre">numba_dppy.offload_to_sycl_device(SYCL_device)</span></code>. Please look at method <code class="code docutils literal notranslate"><span class="pre">select_device_ndarray()</span></code> in the example below.</p>
</dd>
</dl>
</li>
<li><dl>
<dt>Array with __sycl_usm_array_interface__ attribute</dt><dd><p>Numba-dppy supports the Compute Follows Data semantics in this case. Compute Follows Data stipulates that computation must be off-loaded to device where data is resident.</p>
<dl>
<dt>Expected behavior in different cases:</dt><dd><ul>
<li><p>Users are allowed to mix arrays created using equivalent SYCL queues. Where equivalent queues are defined as:</p>
<blockquote>
<div><dl class="simple">
<dt>Two SYCL queues are equivalent if they have the same:</dt><dd><ol class="arabic simple">
<li><p>SYCL context</p></li>
<li><p>SYCL device</p></li>
<li><p>Same queue properties</p></li>
</ol>
</dd>
</dl>
</div></blockquote>
</li>
<li><p>All usm-types are accessible from device. Users can mix arrays with different usm-type as long as they were allocated using the equvalent SYCL queue.</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</li>
</ul>
<section id="example">
<h2>Example<a class="headerlink" href="#example" title="Permalink to this headline"></a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright 2021 Intel Corporation</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#      http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">dpctl</span>
<span class="kn">import</span> <span class="nn">dpctl.tensor</span> <span class="k">as</span> <span class="nn">dpt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">numba_dppy</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">We support passing arrays of two types to a @numba_dppy.kernel decorated</span>
<span class="sd">function.</span>

<span class="sd">1. numpy.ndarray</span>
<span class="sd">2. Any array with __sycl_usm_array_interface__ (SUAI) attribute.</span>

<span class="sd">Users are not allowed to mix the type of arrays passed as arguments. As in, all</span>
<span class="sd">the arguments passed to a @numba_dppy.kernel has to have the same type. For</span>
<span class="sd">example, if the first array argument is of type numpy.ndarray the rest of the</span>
<span class="sd">array arguments will also have to be of type numpy.ndarray.</span>

<span class="sd">The following are how users can specify in which device they want to offload</span>
<span class="sd">their computation.</span>

<span class="sd">1. numpy.ndarray</span>
<span class="sd">    Using context manager provided by Numba_dppy. Please look at method:</span>
<span class="sd">        select_device_ndarray()</span>

<span class="sd">2. Array with __sycl_usm_array_interface__ attribute</span>
<span class="sd">    We follow compute follows data which states that the device where the</span>
<span class="sd">    data resides will be selected for computation. Please look at method:</span>
<span class="sd">         select_device_SUAI()</span>

<span class="sd">    Users can mix SUAI arrays created using equivalent SYCL queues.</span>
<span class="sd">    Two SYCL queues are equivalent if they have the same:</span>
<span class="sd">        1. SYCL context</span>
<span class="sd">        2. SYCL device</span>
<span class="sd">        3. Same queue properties</span>
<span class="sd">&#39;&#39;&#39;</span>


<span class="nd">@numba_dppy</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">sum_kernel</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">numba_dppy</span><span class="o">.</span><span class="n">get_global_id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">allocate_SUAI_data</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">got</span><span class="p">,</span> <span class="n">usm_type</span><span class="p">,</span> <span class="n">queue</span><span class="p">):</span>
    <span class="n">da</span> <span class="o">=</span> <span class="n">dpt</span><span class="o">.</span><span class="n">usm_ndarray</span><span class="p">(</span>
        <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">buffer</span><span class="o">=</span><span class="n">usm_type</span><span class="p">,</span>
        <span class="n">buffer_ctor_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;queue&quot;</span><span class="p">:</span> <span class="n">queue</span><span class="p">},</span>
    <span class="p">)</span>
    <span class="n">da</span><span class="o">.</span><span class="n">usm_data</span><span class="o">.</span><span class="n">copy_from_host</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="s2">&quot;|u1&quot;</span><span class="p">))</span>

    <span class="n">db</span> <span class="o">=</span> <span class="n">dpt</span><span class="o">.</span><span class="n">usm_ndarray</span><span class="p">(</span>
        <span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">b</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">buffer</span><span class="o">=</span><span class="n">usm_type</span><span class="p">,</span>
        <span class="n">buffer_ctor_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;queue&quot;</span><span class="p">:</span> <span class="n">queue</span><span class="p">},</span>
    <span class="p">)</span>
    <span class="n">db</span><span class="o">.</span><span class="n">usm_data</span><span class="o">.</span><span class="n">copy_from_host</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="s2">&quot;|u1&quot;</span><span class="p">))</span>

    <span class="n">dc</span> <span class="o">=</span> <span class="n">dpt</span><span class="o">.</span><span class="n">usm_ndarray</span><span class="p">(</span>
        <span class="n">got</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">got</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">buffer</span><span class="o">=</span><span class="n">usm_type</span><span class="p">,</span>
        <span class="n">buffer_ctor_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;queue&quot;</span><span class="p">:</span> <span class="n">queue</span><span class="p">},</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">da</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">dc</span>


<span class="c1"># ==========================================================================</span>
<span class="k">def</span> <span class="nf">select_device_ndarray</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">got</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="c1"># This context manager is specifying to use the Opencl GPU.</span>
    <span class="k">with</span> <span class="n">numba_dppy</span><span class="o">.</span><span class="n">offload_to_sycl_device</span><span class="p">(</span><span class="s2">&quot;opencl:gpu&quot;</span><span class="p">):</span>
        <span class="n">sum_kernel</span><span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">](</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">got</span><span class="p">)</span>

    <span class="n">expected</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>

    <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">got</span><span class="p">,</span> <span class="n">expected</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Correct result when numpy.ndarray is passed!&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">select_device_SUAI</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">usm_type</span> <span class="o">=</span> <span class="s2">&quot;device&quot;</span>

    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">got</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="n">device</span> <span class="o">=</span> <span class="n">dpctl</span><span class="o">.</span><span class="n">SyclDevice</span><span class="p">(</span><span class="s2">&quot;opencl:gpu&quot;</span><span class="p">)</span>
    <span class="n">queue</span> <span class="o">=</span> <span class="n">dpctl</span><span class="o">.</span><span class="n">SyclQueue</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># We are allocating the data in Opencl GPU and this device</span>
    <span class="c1"># will be selected for compute.</span>
    <span class="n">da</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">dc</span> <span class="o">=</span> <span class="n">allocate_SUAI_data</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">got</span><span class="p">,</span> <span class="n">usm_type</span><span class="p">,</span> <span class="n">queue</span><span class="p">)</span>

    <span class="c1"># Users don&#39;t need to specify where the computation will</span>
    <span class="c1"># take place. It will be inferred from data.</span>
    <span class="n">sum_kernel</span><span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">](</span><span class="n">da</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">dc</span><span class="p">)</span>

    <span class="n">dc</span><span class="o">.</span><span class="n">usm_data</span><span class="o">.</span><span class="n">copy_to_host</span><span class="p">(</span><span class="n">got</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="s2">&quot;|u1&quot;</span><span class="p">))</span>

    <span class="n">expected</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>

    <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">got</span><span class="p">,</span> <span class="n">expected</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Correct result when array with __sycl_usm_array_interface__ is passed!&quot;</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">select_device_ndarray</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">select_device_SUAI</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="atomic-operations.html" class="btn btn-neutral float-left" title="Supported Atomic Operations" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="reduction.html" class="btn btn-neutral float-right" title="Reduction on SYCL-supported Devices" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Intel.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>