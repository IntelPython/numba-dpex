

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Features &mdash; numba-dppy 0.12.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="numba-dppy" href="INDEX.html" />
    <link rel="prev" title="Welcome to numba-dppy’s documentation!" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> numba-dppy
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Features</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#new-decorator">New Decorator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#device-environment">Device Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="#device-array">Device Array</a></li>
<li class="toctree-l2"><a class="reference internal" href="#math-kernels">Math Kernels</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#examples">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#sum-of-two-1d-arrays">Sum of two 1d arrays</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ndarray-support">ndArray Support</a></li>
<li class="toctree-l2"><a class="reference internal" href="#reduction">Reduction</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#parfor-support">ParFor Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="#testing">Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="INDEX.html">numba-dppy</a></li>
<li class="toctree-l1"><a class="reference internal" href="DEBUGGING.html">Debugging with GDB</a></li>
<li class="toctree-l1"><a class="reference internal" href="CONTRIBUTING.html">Contributing</a></li>
</ul>
<p class="caption"><span class="caption-text">For DPPY users</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dppy/index.html">Numba for DPPY GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="dppy-reference/index.html">DPPY Python Reference</a></li>
</ul>
<p class="caption"><span class="caption-text">NumPy support through &#64;njit</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy_support/numpy.html">Numpy support</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">numba-dppy</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Features</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/HowTo.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="features">
<h1>Features<a class="headerlink" href="#features" title="Permalink to this headline">¶</a></h1>
<p>DPPY is currently implemented using OpenCL 2.1. The features currently available
are listed below with the help of sample code snippets. In this release we have
the implementation of the OAK approach described in MS138 in section 4.3.2. The
new decorator is described below.</p>
<p>To access the features driver module have to be imported from numba_dppy.dppy_driver</p>
<div class="section" id="new-decorator">
<h2>New Decorator<a class="headerlink" href="#new-decorator" title="Permalink to this headline">¶</a></h2>
<p>The new decorator included in this release is <em>numba_dppy.kernel</em>. Currently this decorator
takes only one option <em>access_types</em> which is explained below with the help of an example.
Users can write OpenCL tpye kernels where they can identify the global id of the work item
being executed. The supported methods inside a decorated function are:</p>
<ul class="simple">
<li><p>numba_dppy.get_global_id(dimidx)</p></li>
<li><p>numba_dppy.get_local_id(dimidx)</p></li>
<li><p>numba_dppy.get_group_num(dimidx)</p></li>
<li><p>numba_dppy.get_num_groups(dimidx)</p></li>
<li><p>numba_dppy.get_work_dim()</p></li>
<li><p>numba_dppy.get_global_size(dimidx)</p></li>
<li><p>numba_dppy.get_local_size(dimidx)</p></li>
</ul>
<p>Currently no support is provided for local memory in the device and everything is in the
global memory. Barrier and other memory fences will be provided once support for local
memory is completed.</p>
</div>
<div class="section" id="device-environment">
<h2>Device Environment<a class="headerlink" href="#device-environment" title="Permalink to this headline">¶</a></h2>
<p>To invoke a kernel a device environemnt is required. The device environment can be
initialized by the following methods:</p>
<ul class="simple">
<li><p>driver.runtime.get_gpu_device()</p></li>
<li><p>driver.runtime.get_cpu_device()</p></li>
</ul>
</div>
<div class="section" id="device-array">
<h2>Device Array<a class="headerlink" href="#device-array" title="Permalink to this headline">¶</a></h2>
<p>Device arrays are used for representing memory buffers in the device. Device Array
supports only ndarrays in this release. Convenience
methods are provided to allocate a memory buffer represnting ndarrays in the device.
They are:</p>
<ul class="simple">
<li><dl class="simple">
<dt>device_env.copy_array_to_device(ndarray)<span class="classifier">Allocate buffer of size ndarray</span></dt><dd><p>and copy the data from host to
device.</p>
</dd>
</dl>
</li>
<li><p>driver.DeviceArray(device_env.get_env_ptr(), ndarray) :   Allocate buffer of size ndarray.</p></li>
</ul>
<p>Primitive types are passed by value to the kernel, currently supported are int, float, double.</p>
</div>
<div class="section" id="math-kernels">
<h2>Math Kernels<a class="headerlink" href="#math-kernels" title="Permalink to this headline">¶</a></h2>
<p>This release has support for math kernels. See numba_dppy/tests/dppy/test_math_functions.py
for more details.</p>
</div>
</div>
<div class="section" id="examples">
<h1>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h1>
<div class="section" id="sum-of-two-1d-arrays">
<h2>Sum of two 1d arrays<a class="headerlink" href="#sum-of-two-1d-arrays" title="Permalink to this headline">¶</a></h2>
<p>Full example can be found at numba_dppy/examples/sum.py.</p>
<p>To write a program that sums two 1d arrays we at first need a OpenCL device environment.
We can get the environment by using <em>ocldrv.runtime.get_gpu_device()</em> for getting the
GPU environment or <em>ocldrv.runtime.get_cpu_device(data)</em> for the CPU environment. We then
need to copy the data (which has to be an ndarray) to the device (CPU or GPU) through OpenCL,
where <em>device_env.copy_array_to_device(data)</em> will read the ndarray and copy that to the device
and <em>ocldrv.DeviceArray(device_env.get_env_ptr(), data)</em> will create a buffer in the device
that has the same memory size as the ndarray being passed. The OpenCL Kernel in the
folllowing example is <em>data_parallel_sum</em>. To get the id of the work item we are currently
executing we need to use the  <em>numba_dppy.get_global_id(0)</em>, since this example only 1 dimension
we only need to get the id in dimension 0.</p>
<p>While invoking the kernel we need to pass the device environment and the global work size.
After the kernel is executed we want to get the data that contains the sum of the two 1d arrays
back to the host and we can use <em>device_env.copy_array_from_device(ddata)</em>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@numba_dppy</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">data_parallel_sum</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">numba_dppy</span><span class="o">.</span><span class="n">get_global_id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

<span class="n">global_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">N</span> <span class="o">=</span> <span class="n">global_size</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="c1"># Select a device for executing the kernel</span>
<span class="n">device_env</span> <span class="o">=</span> <span class="kc">None</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">device_env</span> <span class="o">=</span> <span class="n">ocldrv</span><span class="o">.</span><span class="n">runtime</span><span class="o">.</span><span class="n">get_gpu_device</span><span class="p">()</span>
<span class="k">except</span><span class="p">:</span>
     <span class="k">try</span><span class="p">:</span>
        <span class="n">device_env</span> <span class="o">=</span> <span class="n">ocldrv</span><span class="o">.</span><span class="n">runtime</span><span class="o">.</span><span class="n">get_cpu_device</span><span class="p">()</span>
<span class="k">except</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">SystemExit</span><span class="p">()</span>

<span class="c1"># Copy the data to the device</span>
<span class="n">dA</span> <span class="o">=</span> <span class="n">device_env</span><span class="o">.</span><span class="n">copy_array_to_device</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">dB</span> <span class="o">=</span> <span class="n">device_env</span><span class="o">.</span><span class="n">copy_array_to_device</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="n">dC</span> <span class="o">=</span> <span class="n">ocldrv</span><span class="o">.</span><span class="n">DeviceArray</span><span class="p">(</span><span class="n">device_env</span><span class="o">.</span><span class="n">get_env_ptr</span><span class="p">(),</span> <span class="n">c</span><span class="p">)</span>

<span class="n">data_parallel_sum</span><span class="p">[</span><span class="n">device_env</span><span class="p">,</span> <span class="n">global_size</span><span class="p">](</span><span class="n">dA</span><span class="p">,</span> <span class="n">dB</span><span class="p">,</span> <span class="n">dC</span><span class="p">)</span>
<span class="n">device_env</span><span class="o">.</span><span class="n">copy_array_from_device</span><span class="p">(</span><span class="n">dC</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="ndarray-support">
<h2>ndArray Support<a class="headerlink" href="#ndarray-support" title="Permalink to this headline">¶</a></h2>
<p>Support for passing ndarray directly to kernels is also supported.</p>
<p>Full example can be found at numba_dppy/examples/sum_ndarray.py</p>
<p>For availing this feature instead of creating device buffers explicitly like the previous
example, users can directly pass the ndarray to the kernel. Internally it will result in
copying the existing data in the ndarray to the device and will copy it back after the kernel
is done executing.</p>
<p>In the previous example we can see some redundant work being done. The buffer
that will hold the result of the summation in the device does not need to be copied from the host
and the input data which will be added does not need to be copied back to the host after the
kernel has executed. To reduce doing redundant work, users can provide hints to the compiler
using the access_types to the function decorator. Currently, there are three access types:
<em>read_only</em> meaning data will only be copied from host to device, <em>write_only</em> meaning memory
will be allocated in device and will be copied back to host and <em>read_write</em> which will both
copy data to and from device.</p>
</div>
<div class="section" id="reduction">
<h2>Reduction<a class="headerlink" href="#reduction" title="Permalink to this headline">¶</a></h2>
<p>This example will demonstrate a sum reduction of 1d array.</p>
<p>Full example can be found at numba_dppy/examples/sum_reduction.py.</p>
<p>In this example to sum the 1d array we invoke the Kernel multiple times.
This can be implemented by invoking the kernel once, but that requires
support for local device memory and barrier, which is a work in progress.</p>
</div>
</div>
<div class="section" id="parfor-support">
<h1>ParFor Support<a class="headerlink" href="#parfor-support" title="Permalink to this headline">¶</a></h1>
<p><em>Parallel For</em> is supported in this release for upto 3 dimensions.</p>
<p>Full examples can be found in numba_dppy/examples/pa_examples/</p>
</div>
<div class="section" id="testing">
<h1>Testing<a class="headerlink" href="#testing" title="Permalink to this headline">¶</a></h1>
<p>All examples can be found in numba_dppy/examples/</p>
<p>All tests can be found in numba_dppy/tests/dppy and can be triggered by the following command:</p>
<p><code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">numba.runtests</span> <span class="pre">numba_dppy.tests</span></code></p>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="INDEX.html" class="btn btn-neutral float-right" title="numba-dppy" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="Welcome to numba-dppy’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, Intel

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>